{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-TXepoSMWK6",
        "outputId": "5232ec95-201d-46c9-c9dd-cfe40094cd81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:334: RuntimeWarning: overflow encountered in cast\n",
            "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:336: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:332: RuntimeWarning: overflow encountered in cast\n",
            "  P[i] = self._priors.logprob(si)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PPSS'), ('love', 'VB'), ('eating', 'VBG'), ('pizza', 'NN'), ('with', 'IN'), ('my', 'PP$'), ('friends', 'NNS')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tag import hmm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "# Sample sentence\n",
        "sentence = \"I love eating pizza with my friends\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Train a Hidden Markov Model POS tagger\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "tagger = trainer.train_supervised(nltk.corpus.brown.tagged_sents())\n",
        "\n",
        "# Tag the tokens\n",
        "tagged_tokens = tagger.tag(tokens)\n",
        "\n",
        "print(tagged_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# Sample sentences\n",
        "sentences = [\n",
        "    [\"I\", \"love\", \"eating\", \"pizza\", \"with\", \"my\", \"friends\"],\n",
        "    [\"They\", \"are\", \"going\", \"to\", \"the\", \"beach\", \"tomorrow\"]\n",
        "]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences, min_count=1)\n",
        "\n",
        "# Get word vectors\n",
        "word_vectors = model.wv\n",
        "\n",
        "# Get vector representation of a word\n",
        "print(\"Vector representation of 'pizza':\", word_vectors['pizza'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajXN12OcMgwG",
        "outputId": "ba520836-216e-4b5f-d875-04da33b6e0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector representation of 'pizza': [ 7.0887972e-03 -1.5679300e-03  7.9474989e-03 -9.4886590e-03\n",
            " -8.0294991e-03 -6.6403709e-03 -4.0034545e-03  4.9892161e-03\n",
            " -3.8135587e-03 -8.3199050e-03  8.4117772e-03 -3.7470020e-03\n",
            "  8.6086961e-03 -4.8957514e-03  3.9185942e-03  4.9220170e-03\n",
            "  2.3926091e-03 -2.8188038e-03  2.8491246e-03 -8.2562361e-03\n",
            " -2.7655398e-03 -2.5911583e-03  7.2490061e-03 -3.4634031e-03\n",
            " -6.5997029e-03  4.3404270e-03 -4.7448516e-04 -3.5975564e-03\n",
            "  6.8824720e-03  3.8723124e-03 -3.9002013e-03  7.7188847e-04\n",
            "  9.1435025e-03  7.7546560e-03  6.3618720e-03  4.6673026e-03\n",
            "  2.3844899e-03 -1.8416261e-03 -6.3712932e-03 -3.0181051e-04\n",
            " -1.5653884e-03 -5.7228567e-04 -6.2628710e-03  7.4340473e-03\n",
            " -6.5914928e-03 -7.2392775e-03 -2.7571463e-03 -1.5154004e-03\n",
            " -7.6357173e-03  6.9824100e-04 -5.3261113e-03 -1.2755442e-03\n",
            " -7.3651113e-03  1.9605684e-03  3.2731986e-03 -2.3138524e-05\n",
            " -5.4483581e-03 -1.7260861e-03  7.0849168e-03  3.7362587e-03\n",
            " -8.8810492e-03 -3.4135508e-03  2.3541022e-03  2.1380198e-03\n",
            " -9.4640078e-03  4.5711659e-03 -8.6569972e-03 -7.3870681e-03\n",
            "  3.4831120e-03 -3.4709584e-03  3.5644709e-03  8.8940905e-03\n",
            " -3.5743224e-03  9.3204249e-03  1.7110384e-03  9.8477742e-03\n",
            "  5.7050432e-03 -9.1494834e-03 -3.3277308e-03  6.5301750e-03\n",
            "  5.6027793e-03  8.7055154e-03  6.9261026e-03  8.0388878e-03\n",
            " -9.8230084e-03  4.2988253e-03 -5.0300765e-03  3.5123860e-03\n",
            "  6.0566878e-03  4.3921317e-03  7.5123594e-03  1.4977157e-03\n",
            " -1.2649416e-03  5.7684006e-03 -5.6395675e-03  3.8591625e-05\n",
            "  9.4565870e-03 -5.4812501e-03  3.8142789e-03 -8.1130210e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "# Initialize WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize words\n",
        "words = [\"running\", \"ate\", \"cars\"]\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "\n",
        "print(lemmatized_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SuRtAF-M0E2",
        "outputId": "08cf2d25-ae0d-41c0-a4a0-40c8c45539d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['running', 'ate', 'car']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a70VAi6sM5wu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}